{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/work/eggNOGbyClass/'\n",
      "/nobackup1c/users/payette/eggNOGbyClass\n"
     ]
    }
   ],
   "source": [
    "import ete3\n",
    "import re\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import igraph as ig\n",
    "import pickle as pkl\n",
    "\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.stats            import mannwhitneyu\n",
    "from collections            import Counter\n",
    "\n",
    "ncbi = ete3.NCBITaxa()\n",
    "%cd /work/eggNOGbyClass/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_genomes = pd.read_csv('genomes.tab',\n",
    "                              sep='\\t',\n",
    "                              index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCDG_sampled_genomes = pd.read_excel('ABCDG_tree_taxa.xlsx')  #ABCDG tree genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCDG_sampled_genomes = ABCDG_sampled_genomes[ABCDG_sampled_genomes['TaxID'] != 2762020] #Exclude this taxa b/c error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1097.0, 1219.0, 33072.0, 198252.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pd.DataFrame(sampled_genomes.species_taxid).species_taxid.head().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = pd.DataFrame()\n",
    "for taxid in ABCDG_sampled_genomes['TaxID'].unique():\n",
    "    if pd.isna(taxid):\n",
    "        continue\n",
    "    lineages = lineages.append({tax_rank: tmp_taxid \n",
    "                                 for tmp_taxid, tax_rank in ncbi.get_rank(ncbi.get_lineage(taxid)).items()},\n",
    "                                ignore_index=True)\n",
    "lineages = lineages.reindex(columns=['class', 'family',  'genus', 'phylum',\n",
    "                                     'order', 'species', 'superkingdom']).copy()\n",
    "lineages = lineages.query('superkingdom == 2').copy()\n",
    "\n",
    "lineages.loc[lineages['phylum']==1224, 'phylum'] = lineages.loc[lineages['phylum']==1224, 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>phylum</th>\n",
       "      <th>order</th>\n",
       "      <th>species</th>\n",
       "      <th>superkingdom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>191410.0</td>\n",
       "      <td>191412.0</td>\n",
       "      <td>256319.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>191411.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>191410.0</td>\n",
       "      <td>191412.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>191411.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>191410.0</td>\n",
       "      <td>191412.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>191411.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>191410.0</td>\n",
       "      <td>191412.0</td>\n",
       "      <td>100715.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>191411.0</td>\n",
       "      <td>100716.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>191410.0</td>\n",
       "      <td>191412.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>191411.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>191410.0</td>\n",
       "      <td>191412.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>191411.0</td>\n",
       "      <td>337090.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class    family     genus  phylum     order   species  superkingdom\n",
       "101  191410.0  191412.0  256319.0  1090.0  191411.0    1097.0           2.0\n",
       "102  191410.0  191412.0    1091.0  1090.0  191411.0    1092.0           2.0\n",
       "103  191410.0  191412.0    1101.0  1090.0  191411.0    1102.0           2.0\n",
       "104  191410.0  191412.0  100715.0  1090.0  191411.0  100716.0           2.0\n",
       "204  191410.0  191412.0    1099.0  1090.0  191411.0    1100.0           2.0\n",
       "221  191410.0  191412.0    1091.0  1090.0  191411.0  337090.0           2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineages.loc[lineages['phylum']==1090] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_groups  = pd.read_parquet('working_eggNOG_groups.parquet')\n",
    "working_trees   = pd.read_parquet('working_eggNOG_trees.parquet' )\n",
    "eggNOG_taxonomy = pd.read_parquet('eggNOG_taxonomy.parquet'      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances(group_id):\n",
    "    \n",
    "    tree = ete3.Tree(working_trees.loc[group_id, 'tree'])\n",
    "\n",
    "    leaf_names = []\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if node.is_leaf():\n",
    "            leaf_names.append(node.name)\n",
    "        else:\n",
    "            node.name = 'node_%i' % count\n",
    "    leaf_names = np.array(leaf_names)\n",
    "\n",
    "    nodes         = []\n",
    "    children      = []\n",
    "    branch_length = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                nodes.append(         node.name)\n",
    "                children.append(     child.name)\n",
    "                branch_length.append(child.dist)\n",
    "\n",
    "    branch_length_df                  = pd.DataFrame()\n",
    "    branch_length_df['node']          = nodes\n",
    "    branch_length_df['child']         = children\n",
    "    branch_length_df['branch_length'] = branch_length\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges=branch_length_df[['node', \n",
    "                                                      'child', \n",
    "                                                      'branch_length']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights=True)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                                   target=leaf_names, \n",
    "                                                                   weights='weight'))\n",
    "                              )\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_taxa_graph(dist_matrix, phyla):\n",
    "    triu_indices       = np.triu_indices_from(dist_matrix, k=1)\n",
    "    \n",
    "    edge_list                 = pd.DataFrame()\n",
    "    edge_list['phylum1']      = phyla[triu_indices[0]]\n",
    "    edge_list['phylum2']      = phyla[triu_indices[1]]\n",
    "    edge_list['sequence1']    = dist_matrix.index[triu_indices[0]]\n",
    "    edge_list['sequence2']    = dist_matrix.index[triu_indices[1]]\n",
    "    edge_list['distance']     = dist_matrix.values[triu_indices]\n",
    "    edge_list['inverse_dist'] = np.e**np.negative(edge_list.distance)\n",
    "\n",
    "    graph  = ig.Graph.TupleList(edges=edge_list[['sequence1', \n",
    "                                                 'sequence2', \n",
    "                                                 'inverse_dist']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights =True)\n",
    "    \n",
    "    return(edge_list, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cles(lessers, greaters):\n",
    "    #\n",
    "    # https://github.com/ajschumacher/cles/blob/master/cles.py\n",
    "    #\n",
    "    \"\"\"Common-Language Effect Size\n",
    "    Probability that a random draw from `greater` is in fact greater\n",
    "    than a random draw from `lesser`.\n",
    "    Args:\n",
    "      lesser, greater: Iterables of comparables.\n",
    "    \"\"\"\n",
    "    if len(lessers) == 0 and len(greaters) == 0:\n",
    "        raise ValueError('At least one argument must be non-empty')\n",
    "    # These values are a bit arbitrary, but make some sense.\n",
    "    # (It might be appropriate to warn for these cases.)\n",
    "    if len(lessers) == 0:\n",
    "        return 1\n",
    "    if len(greaters) == 0:\n",
    "        return 0\n",
    "    numerator = 0\n",
    "    lessers, greaters = sorted(lessers), sorted(greaters)\n",
    "    lesser_index = 0\n",
    "    for greater in greaters:\n",
    "        while lesser_index < len(lessers) and lessers[lesser_index] < greater:\n",
    "            lesser_index += 1\n",
    "        numerator += lesser_index  # the count less than the greater\n",
    "    denominator = len(lessers) * len(greaters)\n",
    "    return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_cluster(reference_phylum, minimal_freq_phyla, cluster_edges, cluster_nodes):\n",
    "\n",
    "    #\n",
    "    # store distances between reference phylum and others\n",
    "    cluster_dists = pd.DataFrame(columns=['phylum', 'median', 'distances'])\n",
    "\n",
    "    #\n",
    "    # traverse all phylum pairs containing the reference phylum\n",
    "    for phylum in minimal_freq_phyla:\n",
    "        if phylum == reference_phylum:\n",
    "            continue\n",
    "\n",
    "        inter_phyla = cluster_edges.loc[((cluster_edges.phylum1==reference_phylum) & (cluster_edges.phylum2==phylum)) |\\\n",
    "                                        ((cluster_edges.phylum2==reference_phylum) & (cluster_edges.phylum1==phylum))]\n",
    "        \n",
    "        #\n",
    "        # create a quadratic matrix of pairwise distances between phyla\n",
    "        #   rows and columns must be unique pairs of sequence names\n",
    "        indices     = np.unique(inter_phyla[['sequence1', 'sequence2']])\n",
    "        adjacencies = pd.DataFrame(index  =indices, \n",
    "                                   columns=indices,\n",
    "                                   data   =0.0)\n",
    "        \n",
    "        #\n",
    "        # add distances between sequences from the edge list to the quadratic matrix\n",
    "        #   as the matrix is quadratic, add values to both directions\n",
    "        indexer     = adjacencies.index.get_indexer\n",
    "        adjacencies.values[indexer(inter_phyla.sequence1), indexer(inter_phyla.sequence2)] = inter_phyla.distance.values\n",
    "        adjacencies.values[indexer(inter_phyla.sequence2), indexer(inter_phyla.sequence1)] = inter_phyla.distance.values\n",
    "\n",
    "        #\n",
    "        # sum the obtained distances into a single cell\n",
    "        tmp_closest_to_phylum = adjacencies.loc[cluster_nodes.loc[cluster_nodes.phylum==reference_phylum, 'name'],\n",
    "                                                cluster_nodes.loc[cluster_nodes.phylum==phylum,           'name']].sum()\n",
    "        tmp_closest_to_phylum.sort_values(inplace=True)\n",
    "        #\n",
    "        # and grab the five sequences from <phylum> closest to all from <reference phylum>\n",
    "        tmp_closest_to_phylum = tmp_closest_to_phylum.index[:5]\n",
    "\n",
    "        try:\n",
    "            #\n",
    "            # get all inter-phyla distances between\n",
    "            distances_to_reference_phylum = adjacencies.loc[\n",
    "                #\n",
    "                # all sequences from <reference phylum>\n",
    "                cluster_nodes.loc[cluster_nodes.phylum==reference_phylum, 'name'],\n",
    "                #\n",
    "                # the 5 sequences from <phylum> closest to <reference phylum>\n",
    "                tmp_closest_to_phylum\n",
    "            ].values.flatten()\n",
    "        except IndexError:\n",
    "            continue        \n",
    "\n",
    "        cluster_dists = cluster_dists.append(pd.Series(data =[phylum, \n",
    "                                                              np.median(distances_to_reference_phylum), \n",
    "                                                              distances_to_reference_phylum], \n",
    "                                                       index=['phylum', 'median', 'distances']),\n",
    "                                             ignore_index=True)\n",
    "    return(cluster_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phyla_evol_distances(group_id):    \n",
    "    dist_matrix = get_pairwise_distances(group_id)\n",
    "\n",
    "    taxids = [int(leaf.split('.')[0]) for leaf in dist_matrix.index]\n",
    "    phyla  = eggNOG_taxonomy.loc[taxids, 'phylum'].values.astype(int)\n",
    "\n",
    "    edge_list, graph  = create_taxa_graph(dist_matrix, phyla)\n",
    "\n",
    "    random.seed(12345)\n",
    "    clusters = graph.community_multilevel(weights='weight')\n",
    "\n",
    "    node_data = pd.DataFrame(columns=['name', 'phylum', 'cluster'],\n",
    "                             data   =zip(dist_matrix.index, \n",
    "                                         phyla, \n",
    "                                         clusters.membership)\n",
    "                            )\n",
    "    \n",
    "    cluster_evol_relations = {}\n",
    "    \n",
    "    target_phyla = {1090,    # chlorobi\n",
    "                    1117,    # cyanobacteria\n",
    "                    200795,  # chloroflexi\n",
    "                    976,     # bacteroidetes #\n",
    "                    1134404, # ignavibacteriae #\n",
    "                    1798710, # melainabacteria #\n",
    "                    28211,   # Alphaproteobacteria\n",
    "                    28216,   # Betaproteobacteria\n",
    "                    1236,    # Gammaproteobacteria\n",
    "                    28221,   # Deltaproteobacteria\n",
    "                    29547,   # Epsilonproteobacteria #\n",
    "                    580370,  # Zetaproteobacteria #\n",
    "                    1807140} # Acidithiobacillia #\n",
    "    \n",
    "    #target_phyla = { 28211,          # Alpha\n",
    "    #                 28216,          # Beta\n",
    "    #                 28221,          # Delta\n",
    "    #                 1236            # Gamma\n",
    "    #               }\n",
    "    \n",
    "    #target_phyla = {1090,    # chlorobi\n",
    "    #                1117,    # cyanobacteria\n",
    "    #                1224,    # proteobacteria\n",
    "    #                200795,  # chloroflexi\n",
    "    #                976,     # bacteroidetes\n",
    "    #                1134404, # ignavibacteriae\n",
    "    #                1798710} # melainabacteria\n",
    "\n",
    "    for cluster_num in set(clusters.membership):\n",
    "        \n",
    "        cluster_nodes      = node_data[node_data.cluster==cluster_num]\n",
    "        minimal_freq_phyla = [phylum \n",
    "                              for phylum, frequency in Counter(cluster_nodes.phylum).items() \n",
    "                              if frequency>=5   # at least five sequences from a phylum\n",
    "                              and phylum > 0]   # given pandas manipulation, unknown phyla are represented \n",
    "                                                #   as NAN, which when forced to be int are negative numbers\n",
    "                                                #   that is why we ignore phylum taxids smaller than zero...\n",
    "       \n",
    "        #\n",
    "        # if there are fewer than two phyla of interested within the tree cluster there is no reason to\n",
    "        #   assess it...\n",
    "        if len( target_phyla.intersection( minimal_freq_phyla ) ) < 2:\n",
    "            continue\n",
    "        \n",
    "        cluster_evol_relations[cluster_num] = {}\n",
    "        \n",
    "        #\n",
    "        # filter patristic distances from the whole tree to only those between sequences within the cluster\n",
    "        cluster_edges = edge_list.loc[(edge_list.sequence1.isin(cluster_nodes.name)) &\n",
    "                                      (edge_list.sequence2.isin(cluster_nodes.name)),\n",
    "                                      ['phylum1', 'phylum2', 'sequence1', 'sequence2', 'distance']]\n",
    "\n",
    "        #\n",
    "        # filter again, leaving only between sequences whose phylum fulfills the minimal frequency\n",
    "        cluster_edges      = cluster_edges[(cluster_edges.phylum1.isin(minimal_freq_phyla)) &\\\n",
    "                                           (cluster_edges.phylum2.isin(minimal_freq_phyla))]\n",
    "        #\n",
    "        # we will divide all pairwise distances by the cluster's mean\n",
    "        normalizer         = np.median(cluster_edges.distance)\n",
    "        #\n",
    "        # remove all intra-phylum distances\n",
    "        cluster_edges      = cluster_edges[cluster_edges.phylum1 != cluster_edges.phylum2] \n",
    "\n",
    "        #\n",
    "        # assess all inter-phyla distances, using each phylum as a reference to itself\n",
    "        #\n",
    "        for ref_phylum in target_phyla.intersection(minimal_freq_phyla):\n",
    "            cluster_dists = assess_cluster(ref_phylum, \n",
    "                                           minimal_freq_phyla, \n",
    "                                           cluster_edges,\n",
    "                                           cluster_nodes)\n",
    "\n",
    "            #\n",
    "            # sort phyla by its avg. distance to <reference phylum>\n",
    "            cluster_dists.sort_values('median', inplace=True)\n",
    "            cluster_evol_relations[cluster_num][ref_phylum] = {\n",
    "                'df'         :cluster_dists[['phylum', 'median']].copy(),\n",
    "                'significant':False\n",
    "            }\n",
    "            if not cluster_dists.shape[0]:\n",
    "                continue\n",
    "\n",
    "            cluster_evol_relations[cluster_num][ref_phylum]['df']['median']   /= normalizer\n",
    "            \n",
    "            #\n",
    "            # if there is only one <phylum> together with <reference phylum>, the proximity between\n",
    "            #   both is automaticaly significant\n",
    "            if cluster_dists.shape[0] == 1:\n",
    "                cluster_evol_relations[cluster_num][ref_phylum]['significant'] = True\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                #\n",
    "                # test if distances from the closest phylum to <reference phylum> is significantly\n",
    "                #   smaller than distances from the second closest phylum\n",
    "                hypothesis = mannwhitneyu(cluster_dists.iloc[0, 2], \n",
    "                                          cluster_dists.iloc[1, 2], \n",
    "                                          alternative='less')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            else:\n",
    "                #\n",
    "                # both cles lines below should work identically... I am leaving the above because it is the one I\n",
    "                #   used in the paper, no real reason...\n",
    "                effect_size = hypothesis.statistic / (len(cluster_dists.iloc[0, 2])*len(cluster_dists.iloc[1, 2]))\n",
    "#                 effect_size = 1-cles(cluster_dists.iloc[0, 2], cluster_dists.iloc[1, 2])\n",
    "\n",
    "                if hypothesis.pvalue < 0.01 and effect_size < 0.2:\n",
    "                    cluster_evol_relations[cluster_num][ref_phylum]['significant'] = True\n",
    "    \n",
    "    return(group_id, cluster_evol_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.6 s, sys: 790 ms, total: 19.4 s\n",
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('COG0499',\n",
       " {0: {28221: {'df':     phylum    median\n",
       "    9   200783  0.377210\n",
       "    10  200940  0.403762\n",
       "    6   200795  0.483988\n",
       "    4     1117  0.585034\n",
       "    2   201174  0.621263\n",
       "    1     1236  0.655360\n",
       "    5     1239  0.690237\n",
       "    7   508458  0.881394\n",
       "    0      976  0.921519\n",
       "    8   200918  1.039805\n",
       "    3    28211  1.426984,\n",
       "    'significant': False},\n",
       "   976: {'df':     phylum    median\n",
       "    5   200795  1.838172\n",
       "    1   201174  1.861487\n",
       "    4     1239  1.921823\n",
       "    9   200783  1.938473\n",
       "    3     1117  1.941954\n",
       "    6    28221  1.950540\n",
       "    7   508458  1.954504\n",
       "    10  200940  1.973091\n",
       "    0     1236  1.990229\n",
       "    8   200918  2.096431\n",
       "    2    28211  2.324822,\n",
       "    'significant': False},\n",
       "   28211: {'df':     phylum    median\n",
       "    2   201174  1.141171\n",
       "    1     1236  1.653357\n",
       "    4     1239  1.794261\n",
       "    5   200795  1.805575\n",
       "    7   508458  1.825412\n",
       "    9   200783  1.873625\n",
       "    3     1117  1.880878\n",
       "    6    28221  1.890243\n",
       "    10  200940  1.912292\n",
       "    8   200918  1.961074\n",
       "    0      976  2.220374,\n",
       "    'significant': False},\n",
       "   1236: {'df':     phylum    median\n",
       "    4     1239  2.032560\n",
       "    5   200795  2.034837\n",
       "    1   201174  2.049645\n",
       "    7   508458  2.059863\n",
       "    9   200783  2.120409\n",
       "    3     1117  2.128471\n",
       "    6    28221  2.136581\n",
       "    10  200940  2.158399\n",
       "    2    28211  2.209286\n",
       "    8   200918  2.209802\n",
       "    0      976  2.264006,\n",
       "    'significant': False},\n",
       "   200795: {'df':     phylum    median\n",
       "    9   200783  0.442586\n",
       "    4     1117  0.444731\n",
       "    6    28221  0.458760\n",
       "    10  200940  0.480815\n",
       "    2   201174  0.507407\n",
       "    1     1236  0.526722\n",
       "    5     1239  0.640508\n",
       "    7   508458  0.796759\n",
       "    0      976  0.810039\n",
       "    8   200918  0.931446\n",
       "    3    28211  1.335985,\n",
       "    'significant': False},\n",
       "   1117: {'df':     phylum    median\n",
       "    5   200795  0.439948\n",
       "    9   200783  0.576723\n",
       "    6    28221  0.591068\n",
       "    10  200940  0.612854\n",
       "    2   201174  0.619615\n",
       "    1     1236  0.658231\n",
       "    4     1239  0.776733\n",
       "    7   508458  0.908251\n",
       "    0      976  0.922279\n",
       "    8   200918  1.040804\n",
       "    3    28211  1.443540,\n",
       "    'significant': True}},\n",
       "  5: {1807140: {'df':     phylum    median\n",
       "    5     1236  0.360121\n",
       "    7     1117  0.544160\n",
       "    4    28211  0.977781\n",
       "    2  1553900  1.170254\n",
       "    3    28221  1.194188\n",
       "    6    28216  1.198145\n",
       "    1   203682  1.207498\n",
       "    0      976  1.230558,\n",
       "    'significant': True},\n",
       "   976: {'df':     phylum    median\n",
       "    1  1553900  0.605977\n",
       "    3    28211  0.710366\n",
       "    0   203682  0.749568\n",
       "    2    28221  0.826859\n",
       "    4     1236  0.877897\n",
       "    5    28216  0.931647\n",
       "    6     1117  0.989218\n",
       "    7  1807140  1.322022,\n",
       "    'significant': False},\n",
       "   28211: {'df':     phylum    median\n",
       "    4     1236  0.664273\n",
       "    5    28216  0.695135\n",
       "    3    28221  0.696028\n",
       "    1   203682  0.732458\n",
       "    6     1117  0.752260\n",
       "    2  1553900  0.772883\n",
       "    0      976  0.814304\n",
       "    7  1807140  1.155320,\n",
       "    'significant': False},\n",
       "   1236: {'df':     phylum    median\n",
       "    6     1117  0.530480\n",
       "    7  1807140  0.577089\n",
       "    4    28211  0.877430\n",
       "    2  1553900  1.064591\n",
       "    3    28221  1.093181\n",
       "    5    28216  1.097776\n",
       "    1   203682  1.101746\n",
       "    0      976  1.125500,\n",
       "    'significant': False},\n",
       "   1117: {'df':     phylum    median\n",
       "    5     1236  0.424036\n",
       "    6    28216  0.575855\n",
       "    3    28221  0.582101\n",
       "    4    28211  0.673414\n",
       "    1   203682  0.757745\n",
       "    2  1553900  0.878392\n",
       "    0      976  0.930325\n",
       "    7  1807140  1.284944,\n",
       "    'significant': False},\n",
       "   28216: {'df':     phylum    median\n",
       "    5     1236  0.459481\n",
       "    3    28221  0.462178\n",
       "    1   203682  0.522940\n",
       "    6     1117  0.649299\n",
       "    4    28211  0.674084\n",
       "    2  1553900  0.937816\n",
       "    0      976  0.939599\n",
       "    7  1807140  1.275657,\n",
       "    'significant': False},\n",
       "   28221: {'df':     phylum    median\n",
       "    5    28216  0.434481\n",
       "    4     1236  0.519734\n",
       "    3    28211  0.645945\n",
       "    1   203682  0.786536\n",
       "    2  1553900  0.807919\n",
       "    0      976  0.860424\n",
       "    6     1117  0.864218\n",
       "    7  1807140  1.254084,\n",
       "    'significant': False}},\n",
       "  6: {976: {'df':    phylum    median\n",
       "    3    1090  0.541185\n",
       "    2   74201  0.681163\n",
       "    4   57723  0.733699\n",
       "    0   28221  0.791487\n",
       "    5    1236  0.799380\n",
       "    1  201174  1.039215,\n",
       "    'significant': True},\n",
       "   1090: {'df':    phylum    median\n",
       "    2     976  0.428185\n",
       "    3   74201  0.718400\n",
       "    4   57723  0.764116\n",
       "    5    1236  0.825252\n",
       "    0   28221  0.867304\n",
       "    1  201174  1.073059,\n",
       "    'significant': True},\n",
       "   1236: {'df':    phylum    median\n",
       "    3   74201  0.544869\n",
       "    5   57723  0.561156\n",
       "    2     976  0.819401\n",
       "    4    1090  0.917926\n",
       "    0   28221  0.996638\n",
       "    1  201174  1.272251,\n",
       "    'significant': False},\n",
       "   28221: {'df':    phylum    median\n",
       "    1     976  0.818662\n",
       "    2   74201  0.967873\n",
       "    3    1090  0.968777\n",
       "    0  201174  1.003138\n",
       "    4   57723  1.016517\n",
       "    5    1236  1.076551,\n",
       "    'significant': True}}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phyla_evol_distances('COG0499')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20020\n"
     ]
    }
   ],
   "source": [
    "print(len(working_groups.group_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.1 s, sys: 15.7 s, total: 1min 9s\n",
      "Wall time: 8h 26min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool    = multiprocessing.Pool(processes=10, maxtasksperchild=5)\n",
    "results = pool.map_async(get_phyla_evol_distances, working_groups.group_id.values)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ABGD_all_results.pkl', 'wb') as out:\n",
    "    pkl.dump(results.get(), out)\n",
    "del(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
